{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDWI_Workshop_DeepLearning_HandsOn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/neubasi/TDWI2018_UseCaseFirstAISecond/blob/master/TDWI_Workshop_DeepLearning_HandsOn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lhYw7BAVicgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Einleitung\n",
        "Laden der notwenigen Module. Bei Problemem bitte direkt melden."
      ]
    },
    {
      "metadata": {
        "id": "iJNg0_ASVTXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "419c7368-270f-4a8f-ecd7-e7a3f54e9d60"
      },
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Timing\n",
        "from time import time\n",
        "\n",
        "# Aufbereitung und Auswertung\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Laden/installieren des high-level-Frameworks keras\n",
        "!pip install keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oXhIbyGoljYU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Datensatz und Problemstellung\n",
        "\n",
        "Der M(odified) N(ational) I(nstitute of) S(tandards and) T(echnology) Datensatz umfast insgesamt 65.000 Bilder von handschriftlichen Ziffern (0 - 9). Jedes dieser schwarz-weißen Bilder ist 28x28 Pixel groß. Unser Ziel in diesem Workshop ist es, die tatsächliche Zahl bestmöglich vorherzusagen. Zum Vergleich: jede Ziffer kommt gleich oft vor, das heißt die Genauigkeit durch blindes Raten liegt bei 10%. "
      ]
    },
    {
      "metadata": {
        "id": "GYHcTIy5llnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0859be96-3294-47fb-c4f2-4264a2db2c59"
      },
      "cell_type": "code",
      "source": [
        "# Laden des Beispieldatensatz\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# Unterdrücken von unkritischen Warnungen\n",
        "import tensorflow as tf\n",
        "old_v = tf.logging.get_verbosity()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Azu11AOsQvQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "320a3a76-934b-4b7f-dbb4-4f86a468347e"
      },
      "cell_type": "code",
      "source": [
        "# 'one_hot = True' bezieht sich auf die Darstellung der Labels. Das Label\n",
        "# \"8\" wird beispielsweise als [0, 0, 0, 0, 0, 0, 0, 1, 0, 0] dargestellt.\n",
        "# Das ermöglicht die Berechnung getrennter Wahrscheinlichkeiten pro\n",
        "# Klasse.\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
        "\n",
        "train_data = mnist.train.images\n",
        "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
        "eval_data = mnist.test.images\n",
        "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
        "\n",
        "print(\"Pictures in the training set:   {:5d}\".format(train_data.shape[0]))\n",
        "print(\"Pictures in the evaluation set: {:5d}\".format(eval_data.shape[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Pictures in the training set:   55000\n",
            "Pictures in the evaluation set: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hxq_WeCGWobu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Um ein Gefühl für den Datensatz zu bekommen, haben wir je ein Bild von eins bis zehn gesucht und mit dem Befehlt unten geplottet.\n",
        "\n",
        "**Aufgabe 1:** ersetzt die Indizes in **```examples```** mit beliebigen (und beliebig vielen) Zahlen von 0 bis 55.000 bis Sie 5-10 schwer lesbare Bilder gefunden haben. Mit diesem groben Gefühl für die Schwierigkeit der Aufgabe folgende drei Schätzfragen:\n",
        "\n",
        "1. Wie präzise kann ein Mensch diese Bilder erkennen?\n",
        "2. Wie präzise kann ein Algorithmus werden?\n",
        "3. Wie präzise kann ein Algorithmus *vor der Kaffeepause* werden?\n",
        "\n",
        "Alle Schätzungen bitte als Werte zwischen 0 (alle falsch) und 1 (alle richtig) bei den entsprechenden Variablen im unteren Codeblock eintragen.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GuPKfsG6WRab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7ccea054-019b-409a-f474-750d3b683356"
      },
      "cell_type": "code",
      "source": [
        "# Als Backup: [4, 13, 1, 2, 27, 3, 0,  9, 8, 7]\n",
        "examples = [5, 89, 13, 2, 129, 3, 0,  9, 8, 7]\n",
        "\n",
        "human_precision               = 0.9  # zwischen 0 und 1\n",
        "machine_precision_enough_time = 0.99    # zwischen 0 und 1\n",
        "machine_precision_pre_coffee  = 0.80  # zwischen 0 und 1\n",
        "\n",
        "# ------- Ab hier nichts ändern! ----------\n",
        "columns = 5\n",
        "for i, image in enumerate(examples):\n",
        "    plt.subplot(len(examples) / columns + 1, columns, i + 1)\n",
        "    plt.imshow(train_data[image].reshape((28, 28)))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAADYCAYAAACqculUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBQAgMjpfAAAio/MFACCy/wPUypPGYsQ6KQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5e303086d8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sCxXDV1Xlhis",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modellierung\n",
        "\n",
        "Für dieses Notebook beschränken wir uns auf ein sehr einfach gehaltenes neuronales Netz. Wir variieren nur zwei Parameter: **a)** die Anzahl der Schichten und **b)** die Anzahl der Neuronen pro Schicht. Unser Ziel ist herauszufinden, wie weit wir mit diesem sehr simplen Ansatz kommen können. Der folgende Codeblock automatisiert den Bau des Netzwerks und muss einmal ausgeführt, aber nicht verstanden werden."
      ]
    },
    {
      "metadata": {
        "id": "Fh1ek6ZZj80q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2d0f8b95-a789-4fb0-d1b3-f8fd494b28d0"
      },
      "cell_type": "code",
      "source": [
        "def build_model(no_nodes, no_hidden_layers, input_shape):\n",
        "  \n",
        "  # Initialisierung des Netzwerks als sequentielles Model (= Schicht für\n",
        "  # Schicht) mit entsprechendem Input-Layer (jeder Pixel ein isolierter\n",
        "  # Datenpunkt).\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Dense(units=no_nodes, input_dim=input_shape))\n",
        "\n",
        "  # Zusätzliche Anzahl von dichten hidden layers mit konstanter Anzahl von\n",
        "  # Neuronen. Beispiel: no_nodes = 5 und no_hidden_layers = 3 erzeugt\n",
        "  # zusätzlich drei Layer mit jeweils fünf Neuronen.\n",
        "  \n",
        "  for _ in range(no_hidden_layers):\n",
        "    model.add(Dense(units=no_nodes))\n",
        "\n",
        "  # Die finale Schicht normiert die vorhergesagten Wahrscheinlichkeiten\n",
        "  # über alle zehn möglichen Kategorien auf 100%.\n",
        "  \n",
        "  model.add(Dense(units=10, activation='softmax'))\n",
        "  \n",
        "  # Die folgenden Details überschreiten den Rahmen dieses Workshops. Kurz\n",
        "  # gesagt wird hier abschließend definiert auf welche Art das Netzwerk\n",
        "  # trainiert und optimiert wird. Im Ergbnis gibt die Funktion ein\n",
        "  # Netzwerk zurück, dass bereit für das eigentliche Training ist.\n",
        "  \n",
        "  model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u5-5Y5IaaRuR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Aufgabe:** ergänzen bzw. verändern Sie die Liste in ```model_combinations``` so, dass insgesamt zehn verschiedene Netzwerkarchitekturen (Kombinationen aus Layern und Neuronen) berechnet werden. **Rein intuitiv: welche Kombination, glauben Sie, wird wie erfolgreich sein?**\n",
        "\n",
        "**Wichtig:** für diesen Workshop werden wir kein Netzwerk mit mehr als insgesamt 100 Neuronen rechnen, damit die Rechenzeit nicht zu groß wird."
      ]
    },
    {
      "metadata": {
        "id": "7UxRCG4zk4m-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da72e4b8-03d0-4215-9c2d-8ddef0301322"
      },
      "cell_type": "code",
      "source": [
        "# Für jede gewünschte Variante von Netzwerkarchitekturen bitte hier ein Tuple\n",
        "# von zwei Werten angeben:\n",
        "#\n",
        "#         (Anzahl der hidden Layer, Anzahl der Neuronen pro Layer)\n",
        "#\n",
        "# Beim Ausführen der Zelle werden alle Kombinationen einzeln trainiert und\n",
        "# verschiedene Metriken zur Evaluierung eingesammelt.\n",
        "#\n",
        "# Wichtig: der rechnerische Aufwand für das Training wird sehr schnell sehr\n",
        "#          hoch. Für diesen Workshop ist die Trainingszeit deshalb stark\n",
        "#          reduziert.\n",
        "\n",
        "model_combinations = [(1, 1), (2, 50)  ]\n",
        "\n",
        "# ------ Ab hier nichts verändern! ------\n",
        "\n",
        "layers = []\n",
        "nodes = []\n",
        "evals = []\n",
        "trains = []\n",
        "sums = []\n",
        "\n",
        "for (l, n) in model_combinations:\n",
        "  \n",
        "  if(l * n > 100):\n",
        "    print(\"Mehr als insgesamt 100 Neuronen wird zu lange dauern.\")\n",
        "    continue\n",
        "  \n",
        "  model = build_model(no_nodes=n, no_hidden_layers=l,\n",
        "                      input_shape=train_data.shape[1])\n",
        "  model.fit(train_data, train_labels, epochs=3, verbose=0)\n",
        "  layers.append(l)\n",
        "  nodes.append(n)\n",
        "  sums.append(n * l)\n",
        "  trains.append(model.evaluate(train_data, train_labels, verbose=0)[1])\n",
        "  evals.append(model.evaluate(eval_data, eval_labels)[1])\n",
        "                     \n",
        "\n",
        "# Aufbau der Evaluationstabelle\n",
        "comparison = pd.DataFrame({\"no_layers\": layers, \"no_nodes\": nodes,\n",
        "                           \"sum_nodes\": sums, \"evaluation_test\": evals,\n",
        "                           \"evaluation_training\": trains})\n",
        "                     \n",
        "comparison[\"diff_human\"] = comparison.evaluation_test - human_precision\n",
        "comparison[\"diff_machine_pre_coffee\"] = comparison.evaluation_test - machine_precision_pre_coffee\n",
        "comparison[\"diff_machine_enough_time\"] = comparison.evaluation_test - machine_precision_enough_time\n",
        "comparison[\"is_overfitting\"] = comparison.evaluation_training > comparison.evaluation_test\n",
        "\n",
        "comparison = comparison[[\"no_layers\", \"no_nodes\", \"sum_nodes\",\n",
        "                         \"evaluation_training\", \"evaluation_test\",\n",
        "                         \"diff_human\", \"diff_machine_pre_coffee\", \"diff_machine_enough_time\",\n",
        "                         \"is_overfitting\"]]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 43us/step\n",
            "10000/10000 [==============================] - 0s 49us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RX-NJLpk_6lK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "Nach der Berechnung aller angegebenen Modellvariationen, zeigt die untere Tabelle nun eine Zusammenfassung der verschiedenen Evaluationsmetriken:\n",
        "- ```no_layers```, ```no_nodes``` und ```sum_nodes``` sind rein deskriptiv.\n",
        "- ```evaluation_training``` ist die Genauigkeit des Netzes auf den bekannten Daten.\n",
        "- ```evaluation_test``` ist die Genauigkeit des Netzes auf unbekannten Daten.\n",
        "- ```diff_XXXX``` ist der Unterschied zu den Einschätzungen in der vorherigen Aufgabe.\n",
        "\n",
        "**Aufgabe 2:**\n",
        "- Welche Kombination aus Anzahl der Layer und Neuronen schneidet in ```evaluation_test``` am besten ab? Ist das überraschend? \n",
        "- Ist die Anzahl der Schichten oder die der Neuronen wichtiger für das bestmögliche Ergebnis?\n",
        "- Wie schlagen sich die verschiedenen Netze im Vergleich zu euren vorherigen Erwartungen? Ist der Abstand größer oder kleiner als gedacht?\n",
        "- Wie sehr würden Sie dem besten Netz in einem realen Usecase vertrauen?"
      ]
    },
    {
      "metadata": {
        "id": "QRk1AkC8Ry-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "c5ed6f48-c1ca-44dd-ba9a-936ade80db96"
      },
      "cell_type": "code",
      "source": [
        "comparison.sort_values(\"evaluation_test\", ascending=False)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no_layers</th>\n",
              "      <th>no_nodes</th>\n",
              "      <th>sum_nodes</th>\n",
              "      <th>evaluation_training</th>\n",
              "      <th>evaluation_test</th>\n",
              "      <th>diff_human</th>\n",
              "      <th>diff_machine_pre_coffee</th>\n",
              "      <th>diff_machine_enough_time</th>\n",
              "      <th>is_overfitting</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "      <td>0.920291</td>\n",
              "      <td>0.9204</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>0.1204</td>\n",
              "      <td>-0.0696</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.388200</td>\n",
              "      <td>0.3920</td>\n",
              "      <td>-0.5080</td>\n",
              "      <td>-0.4080</td>\n",
              "      <td>-0.5980</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   no_layers  no_nodes  sum_nodes  evaluation_training  evaluation_test  \\\n",
              "1          2        50        100             0.920291           0.9204   \n",
              "0          1         1          1             0.388200           0.3920   \n",
              "\n",
              "   diff_human  diff_machine_pre_coffee  diff_machine_enough_time  \\\n",
              "1      0.0204                   0.1204                   -0.0696   \n",
              "0     -0.5080                  -0.4080                   -0.5980   \n",
              "\n",
              "   is_overfitting  \n",
              "1           False  \n",
              "0           False  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "c2Vb4DQE_4uR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}